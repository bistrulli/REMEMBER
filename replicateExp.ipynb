{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8683d3a",
   "metadata": {},
   "source": [
    "### Setup and Import Section ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be43c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replicateExp.ipynb\n",
    "import os\n",
    "import sys # For robust Colab detection\n",
    "\n",
    "# --- Setup Section ---\n",
    "# This part of the code takes care of preparing the environment, both on Colab and locally.\n",
    "\n",
    "# Check if we are on Google Colab\n",
    "# A more robust way to check if the code is running in Google Colab\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"Running on Google Colab. Setting up environment...\")\n",
    "    # Name of your GitHub repository - IMPORTANT: MAKE SURE THIS MATCHES YOUR REPO NAME\n",
    "    repo_name = \"REMEMBER\" # This should be the actual name of your repository folder\n",
    "    # Ensure the URL is correct for your repository\n",
    "    repo_url = f\"https://github.com/bistrulli/{repo_name}.git\"\n",
    "\n",
    "    # Clone the repository if the directory doesn't already exist\n",
    "    if not os.path.exists(repo_name):\n",
    "        print(f\"Cloning repository '{repo_name}' from {repo_url}...\")\n",
    "        !git clone {repo_url}\n",
    "        if os.path.exists(repo_name):\n",
    "            print(f\"Repository '{repo_name}' cloned successfully.\")\n",
    "        else:\n",
    "            print(f\"Error: Cloning failed or repository directory not found as '{repo_name}'.\")\n",
    "            # Attempt to list current directory contents to help debug\n",
    "            print(\"Current directory contents:\")\n",
    "            !ls -a\n",
    "    else:\n",
    "        print(f\"Repository directory '{repo_name}' already exists. Skipping clone.\")\n",
    "\n",
    "    # Change to the repository directory if it exists\n",
    "    if os.path.isdir(repo_name):\n",
    "        os.chdir(repo_name)\n",
    "        print(f\"Changed directory to: {os.getcwd()}\")\n",
    "    else:\n",
    "        print(f\"Warning: Could not change to directory '{repo_name}'. It does not exist or is not a directory.\")\n",
    "        print(f\"Current directory remains: {os.getcwd()}\")\n",
    "else:\n",
    "    import argparse\n",
    "    print(\"Not running on Google Colab (or Colab detection failed). Assuming local environment.\")\n",
    "    # You might want to add any local-specific setup here if needed\n",
    "\n",
    "# --- End Setup Section ---\n",
    "\n",
    "print(\"Installing required packages...\")\n",
    "!pip install -r requirements.txt\n",
    "print(\"Package installation attempt complete.\")\n",
    "\n",
    "# Attempt to import pm4py to verify installation, especially on Colab\n",
    "try:\n",
    "    import pm4py\n",
    "    print(\"pm4py imported successfully.\")\n",
    "except ImportError:\n",
    "    print(\"Error: pm4py (or one of its dependencies) could not be imported after installation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d81db59-0453-4397-b66f-e6c2f7e344f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from vlmcProcessMining import *\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "from scipy.io import savemat\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pathlib\n",
    "import shutil\n",
    "import tqdm\n",
    "import time\n",
    "import glob\n",
    "import warnings\n",
    "import xml.parsers.expat\n",
    "import warnings\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.log.exporter.xes import exporter as xes_exporter\n",
    "from pm4py.objects.petri_net.obj import PetriNet, Marking\n",
    "from pm4py.objects.petri_net.importer import importer as pnml_importer\n",
    "from pm4py.algo.simulation.playout.petri_net import algorithm as simulator\n",
    "from pm4py.statistics.variants.log import get as variants_module\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.objects.log.util import dataframe_utils\n",
    "import gzip\n",
    "import tempfile\n",
    "import atexit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "noisydir=Path(os.getcwd())/\"data\"/\"noisy_data\"\n",
    "ldir=Path(os.getcwd())/pathlib.Path(\"likelyhood\")\n",
    "dataDir=Path(\"./data/sldpn-reproducibility/experiments/\")\n",
    "trainLogDir=dataDir/Path(\"2-splitlogs\")\n",
    "testLogDir=dataDir/Path(\"2-splitlogstest\")\n",
    "meausreDir=dataDir/Path(\"4-measures\")\n",
    "discoveredStochModel=dataDir/Path(\"3-discoveredstochasticmodels\")\n",
    "enjoySilentDir=Path(os.getcwd())/\"data\"/\"enjoythesilent\"\n",
    "\n",
    "lognames=['bpic12-a','BPI_Challenge_2013_incidents',\n",
    "          'BPI_Challenge_2013_open_problems','BPI_Challenge_2013_closed_problems',\n",
    "          'BPI Challenge 2017 - Offer log','bpic2020-DomesticDeclarations',\n",
    "          'bpic2020-InternationalDeclarations','bpic2020-PrepaidTravelCost',\n",
    "          'bpic2020-RequestForPayment','Sepsis',\n",
    "          'Road_Traffic_Fine_Management_Process']\n",
    "\n",
    "def getVLMCName(inputFile):\n",
    "    vlmcName=None\n",
    "    inputFile=Path(inputFile)\n",
    "    if inputFile.suffix == '.gz':\n",
    "        vlmcName='.'.join(inputFile.stem.split('.')[0:-1])\n",
    "    else:\n",
    "        vlmcName=inputFile.stem\n",
    "    return vlmcName\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e3160a-2914-4299-a04f-270a5351132a",
   "metadata": {},
   "source": [
    "### Mine The VLMC From an Event Log ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c5bc5a-c669-42ba-9e36-e39a17805ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVLMC(inputFile):\n",
    "    readInputFile(inputFile)\n",
    "    vlmcName=getVLMCName(inputFile)\n",
    "    st=time.time()\n",
    "    mineProcess(ecfFile=f\"{os.getcwd()}/data/VLMC/{vlmcName}.ecf\",\n",
    "    infile=f\"{os.getcwd()}/data/converted/{vlmcName}.txt\",\n",
    "    vlmcfile=f\"{os.getcwd()}/data/VLMC/{vlmcName}.vlmc\", \n",
    "    nsim=\"1\", ntime=\"1\", alfa=\"1\")\n",
    "    vlmcTime=time.time()-st\n",
    "    print(f\"VLMC Mined In {vlmcTime}\")\n",
    "    return vlmcTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f062313f-da93-4b8e-be65-13ea20e2bbb2",
   "metadata": {},
   "source": [
    "### Compute Likelihood With VLMC ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06e5a97e-6747-485e-83f3-095e17793421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVLMCLikelyhood(vlmcName=None,traceFile=None):\n",
    "    st=time.time()\n",
    "    ecfFile=pathlib.Path(f\"{os.getcwd()}/data/VLMC/{vlmcName}.ecf\").absolute()\n",
    "    infile=pathlib.Path(f\"{os.getcwd()}/data/converted/{vlmcName}.txt\").absolute()\n",
    "    vlmcfile=pathlib.Path(f\"{os.getcwd()}/data/VLMC/{vlmcName}2.vlmc\").absolute()\n",
    "    vlmc=pathlib.Path(f\"{os.getcwd()}/data/VLMC/{vlmcName}.vlmc\").absolute()\n",
    "    \n",
    "    cwd=(ldir/pathlib.Path(traceFile.name.split(\".\")[0]))\n",
    "    cwd.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    getLikelyhood(\n",
    "        ecfFile=str(ecfFile),\n",
    "        infile=str(infile), #dataset used to learn the vlmc\n",
    "        vlmc=str(vlmc), #input VLMC to use\n",
    "        vlmcfile=str(vlmcfile),  #output VLMC\n",
    "        traces=str(traceFile), #traces to compute likelyhood\n",
    "        cwd=str(cwd),\n",
    "        outFile=\"out.mat\",nsim=\"1\", ntime=\"1\",alfa=\"1\")\n",
    "    liktime=time.time()-st\n",
    "    return liktime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c516b-a2d7-4646-834a-55a92dfbf641",
   "metadata": {},
   "source": [
    "### Preprocess Test Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e488f40e-37ac-4372-beef-ae6ad2d2ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTestDate(inputTrace=None):\n",
    "    datasetName=inputTrace.name\n",
    "    testsetName=f\"{'.'.join(datasetName.split('.')[0:-2])}_test.{'.'.join(datasetName.split('.')[-2:])}\"\n",
    "    testTraceFile=testLogDir/Path(testsetName)\n",
    "    if(not testTraceFile.is_file()):\n",
    "        (testLogDir/Path(datasetName)).rename(testTraceFile)\n",
    "    return testTraceFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c580bd-4fd7-45de-b619-a494ffe5dd92",
   "metadata": {},
   "source": [
    "### Compute uEMSC With VLMC Likelihood ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f63371-2fc7-437d-9f2a-100fe0d92027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uEMSCVLMC(inputLan=None,vlmcName=None):\n",
    "    st=time.time()\n",
    "    cwd=(ldir/pathlib.Path(inputLan.name.split(\".\")[0]))\n",
    "    cwd.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    traceLikName=\".\".join(inputLan.name.split(\".\")[0:-1])+\".lik\"\n",
    "    traceLikFile=cwd/pathlib.Path(traceLikName)\n",
    "    \n",
    "    modelLikName=vlmcName+\".vlmc.lik\"\n",
    "    modelLikFile=cwd/pathlib.Path(modelLikName)\n",
    "    \n",
    "    uEMSC=computeMuEMSC(traceLik=traceLikFile,modelLik=modelLikFile)\n",
    "    emsctime=time.time()-st\n",
    "    return uEMSC,emsctime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eacf83",
   "metadata": {},
   "source": [
    "### Road Traffic Fines Management Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5be5430-9d07-41f2-9a9d-d0b65c046ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproduceVLMVExp():\n",
    "    matching_logs = list(trainLogDir.rglob(\"*.xes.gz[0-9].xes.gz\"))\n",
    "    #Loop over the logs\n",
    "    for log in matching_logs:\n",
    "        #if(\"Hospital\" in str(log) or \"testlogdata\" in str(log) or \"test log\" in str(log)):\n",
    "        #    continue\n",
    "        if(Path(log).name.split('.')[0] not in lognames):\n",
    "            print(f\"skipped {Path(log).name}\")\n",
    "            continue\n",
    "        #create Model from Log\n",
    "        #inputTrace=trainLogDir/Path(\"SERVICES.csv1.xes.gz0.xes.gz\")\n",
    "        inputTrace=log\n",
    "        mctime=createVLMC(inputFile=inputTrace)\n",
    "        \n",
    "        #Process Test Trace\n",
    "        testTrace=prepareTestDate(inputTrace=inputTrace)\n",
    "        readInputFile(inputFile=testTrace)\n",
    "        \n",
    "        #Compute TestLanguage LikelyHood\n",
    "        vlmcName=\".\".join(inputTrace.name.split(\".\")[0:-2])\n",
    "        traceLan=ldir/Path(inputTrace.name.split(\".\")[0])/Path(f\"{vlmcName}_trace.lan\")\n",
    "        testLan=ldir/Path(inputTrace.name.split(\".\")[0])/Path(f\"{vlmcName}_test_trace.lan\")\n",
    "        liktime=getVLMCLikelyhood(vlmcName=vlmcName,traceFile=testLan)\n",
    "        \n",
    "        #Compute uEMSC\n",
    "        uEMSC,uemsctime=uEMSCVLMC(inputLan=testLan,vlmcName=vlmcName)\n",
    "    \n",
    "        uEMSCFile=ldir/Path(inputTrace.name.split(\".\")[0])/Path(f\"{vlmcName}.uemsc\")\n",
    "        uEMSCTimeFile=ldir/Path(inputTrace.name.split(\".\")[0])/Path(f\"{vlmcName}.time\")\n",
    "        np.savetxt(str(uEMSCFile),[uEMSC])\n",
    "        np.savetxt(str(uEMSCTimeFile),[mctime,liktime,uemsctime])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a0fdf9",
   "metadata": {},
   "source": [
    "### Collect VLMC Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a15b9cde-7896-4fcb-9187-4dff1e12505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectVLMCRes():\n",
    "    matching_files = list(ldir.rglob(\"*.uemsc\"))\n",
    "    results=[]\n",
    "    # Print the results\n",
    "    for file in matching_files:\n",
    "        filePath=Path(file)\n",
    "        Logname=filePath.name.split(\".\")[0]\n",
    "        splitIdx=int(re.findall(r'gz(\\d+)\\.uemsc',filePath.name)[0])\n",
    "        uemsc=np.loadtxt(filePath)\n",
    "        #print(Logname,splitIdx,uemsc)\n",
    "        results+=[[Logname,splitIdx,uemsc]]\n",
    "    return pd.DataFrame(results,columns=[\"logname\",\"split\",\"uemsc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7350a5-0ba0-442b-9c0e-1fee0e7fd5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectVLMCTime():\n",
    "    matching_files = list(ldir.rglob(\"*.time\"))\n",
    "    results=[]\n",
    "    # Print the results\n",
    "    for file in matching_files:\n",
    "        filePath=Path(file)\n",
    "        Logname=filePath.name.split(\".\")[0]\n",
    "        splitIdx=int(re.findall(r'gz(\\d+)\\.time',filePath.name)[0])\n",
    "        time=np.loadtxt(filePath)\n",
    "        #print(Logname,splitIdx,uemsc)\n",
    "        results+=[[Logname,splitIdx,time[0],time[1],time[2]]]\n",
    "    return pd.DataFrame(results,columns=[\"logname\",\"split\",\"mctime\",\"liktime\",\"uemsctime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de9b54-e6b3-45b1-8f53-bebdfbaebd85",
   "metadata": {},
   "source": [
    "### Reproduce Papers Plots ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca35036-25ae-4706-b411-0073f42f94f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lognames=baselineRes[\"logname\"].unique()\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "# Create a figure\n",
    "medianprops = dict(linestyle=None, linewidth=0, color='firebrick')\n",
    "meanprops = dict(linestyle=\"-\", linewidth=1.5, color='orange')\n",
    "\n",
    "#fig, ax = plt.subplots(len(lognames),1, figsize=(9, 30))  # 1 row, 2 columns of subplots\n",
    "for i,lname in enumerate(lognames):\n",
    "    #bestMethod=baselineRes[baselineRes['logname']==lname].groupby(by=['dis-tech', 'stoch-tech'])['zemsc'].mean().idxmax()\n",
    "    bestMethods=btech[(btech[\"logname\"]==lname)]\n",
    "    x=[]\n",
    "    names=[]\n",
    "    for bm in bestMethods.to_numpy():\n",
    "        names+=[f\"{bm[1]}_{bm[2]}\"]\n",
    "        values=baselineRes[(baselineRes[\"dis-tech\"]==bm[1]) & (baselineRes[\"stoch-tech\"]==bm[2]) & (baselineRes[\"logname\"]==bm[0])][\"zemsc\"].values\n",
    "        x+=[values.tolist()]\n",
    "\n",
    "    x+=[vlmcRes[vlmcRes[\"logname\"]==lname][\"uemsc\"].values]\n",
    "    names+=[\"VLMC\"]\n",
    "\n",
    "    for nidx in range(len(names)-1):\n",
    "        ks=stats.ks_2samp(x[nidx], x[-1])\n",
    "        if(ks.pvalue<0.05 or len(x[nidx])==0 ):\n",
    "            #names[nidx]+=\"-r\"\n",
    "            pass\n",
    "            \n",
    "    fig=plt.figure(figsize=(10, 4))\n",
    "    plt.boxplot(x,tick_labels=names,showmeans=True,meanline=True,medianprops=medianprops,meanprops=meanprops)\n",
    "    plt.ylabel(\"uEMSC\")\n",
    "    plt.grid()\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.savefig(f'./plots/{lname}.pdf',bbox_inches='tight', pad_inches=0)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
