{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8683d3a",
   "metadata": {},
   "source": [
    "### Setup and Import Section ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be43c17",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mNon è stato possibile avviare il kernel. \n",
      "\u001b[1;31mAvvio del Kernel 'Python 3.13 (Custom)' non riuscito. \n",
      "\u001b[1;31mPer altre informazioni, vedere Jupyter <a href='command:jupyter.viewOutput'>log</a>. Unable to get resolved server information for ms-toolsai.jupyter:_builtin.jupyterServerUrlProvider:31382519-7c6f-4e9e-b64b-a478a01d60c4"
     ]
    }
   ],
   "source": [
    "# replicateExp.ipynb\n",
    "import os\n",
    "import sys # For robust Colab detection\n",
    "\n",
    "# --- Setup Section ---\n",
    "# This part of the code takes care of preparing the environment, both on Colab and locally.\n",
    "\n",
    "# Check if we are on Google Colab\n",
    "# A more robust way to check if the code is running in Google Colab\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"Running on Google Colab. Setting up environment...\")\n",
    "    # Name of your GitHub repository - IMPORTANT: MAKE SURE THIS MATCHES YOUR REPO NAME\n",
    "    repo_name = \"REMEMBER\" # This should be the actual name of your repository folder\n",
    "    # Ensure the URL is correct for your repository\n",
    "    repo_url = f\"https://github.com/bistrulli/{repo_name}.git\"\n",
    "\n",
    "    # Clone the repository if the directory doesn't already exist\n",
    "    if not os.path.exists(repo_name):\n",
    "        print(f\"Cloning repository '{repo_name}' from {repo_url}...\")\n",
    "        !git clone {repo_url}\n",
    "        if os.path.exists(repo_name):\n",
    "            print(f\"Repository '{repo_name}' cloned successfully.\")\n",
    "        else:\n",
    "            print(f\"Error: Cloning failed or repository directory not found as '{repo_name}'.\")\n",
    "            # Attempt to list current directory contents to help debug\n",
    "            print(\"Current directory contents:\")\n",
    "            !ls -a\n",
    "    else:\n",
    "        print(f\"Repository directory '{repo_name}' already exists. Skipping clone.\")\n",
    "\n",
    "    # Change to the repository directory if it exists\n",
    "    if os.path.isdir(repo_name):\n",
    "        os.chdir(repo_name)\n",
    "        print(f\"Changed directory to: {os.getcwd()}\")\n",
    "    else:\n",
    "        print(f\"Warning: Could not change to directory '{repo_name}'. It does not exist or is not a directory.\")\n",
    "        print(f\"Current directory remains: {os.getcwd()}\")\n",
    "else:\n",
    "    import argparse\n",
    "    print(\"Not running on Google Colab (or Colab detection failed). Assuming local environment.\")\n",
    "    # You might want to add any local-specific setup here if needed\n",
    "# --- End GitHub Setup Section ---\n",
    "\n",
    "# Install OpenJDK 17\n",
    "print(\"Updating package list...\")\n",
    "!sudo apt-get update -qq > /dev/null\n",
    "print(\"Installing OpenJDK 17...\")\n",
    "!sudo apt-get install -y openjdk-17-jdk -qq > /dev/null\n",
    "print(\"Setting JAVA_HOME environment variable...\")\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n",
    "# Verify Java version\n",
    "print(\"Verifying Java installation...\")\n",
    "!java -version\n",
    "print(\"Java 17 setup complete.\")\n",
    "\n",
    "print(\"Installing required packages...\")\n",
    "!pip install -r requirements.txt\n",
    "print(\"Package installation attempt complete.\")\n",
    "\n",
    "# Attempt to import pm4py to verify installation, especially on Colab\n",
    "try:\n",
    "    import pm4py\n",
    "    print(\"pm4py imported successfully.\")\n",
    "except ImportError:\n",
    "    print(\"Error: pm4py (or one of its dependencies) could not be imported after installation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d81db59-0453-4397-b66f-e6c2f7e344f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mNon è stato possibile avviare il kernel. \n",
      "\u001b[1;31mAvvio del Kernel 'Python 3.13 (Custom)' non riuscito. \n",
      "\u001b[1;31mPer altre informazioni, vedere Jupyter <a href='command:jupyter.viewOutput'>log</a>. Unable to get resolved server information for ms-toolsai.jupyter:_builtin.jupyterServerUrlProvider:31382519-7c6f-4e9e-b64b-a478a01d60c4"
     ]
    }
   ],
   "source": [
    "\n",
    "from vlmcProcessMining import *\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "from scipy.io import savemat\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pathlib\n",
    "import shutil\n",
    "import tqdm\n",
    "import time\n",
    "import glob\n",
    "import warnings\n",
    "import xml.parsers.expat\n",
    "import warnings\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.log.exporter.xes import exporter as xes_exporter\n",
    "from pm4py.objects.petri_net.obj import PetriNet, Marking\n",
    "from pm4py.objects.petri_net.importer import importer as pnml_importer\n",
    "from pm4py.algo.simulation.playout.petri_net import algorithm as simulator\n",
    "from pm4py.statistics.variants.log import get as variants_module\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.objects.log.util import dataframe_utils\n",
    "import gzip\n",
    "import tempfile\n",
    "import atexit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "ldir=Path(os.getcwd())/\"likelyhood\"\n",
    "dataDir=Path(os.getcwd())/\"data\"\n",
    "vlmcDir=dataDir/\"VLMC\"\n",
    "vlmcDir.mkdir(parents=True, exist_ok=True)\n",
    "convertedDir=dataDir/\"converted\"\n",
    "convertedDir.mkdir(parents=True, exist_ok=True)\n",
    "trainLogDir=dataDir/\"2-splitlogs\"\n",
    "testLogDir=dataDir/\"2-splitlogstest\"\n",
    "\n",
    "lognames=['Road_Traffic_Fine_Management_Process']\n",
    "\n",
    "def getVLMCName(inputFile):\n",
    "    vlmcName=None\n",
    "    inputFile=Path(inputFile)\n",
    "    if inputFile.suffix == '.gz':\n",
    "        vlmcName='.'.join(inputFile.stem.split('.')[0:-1])\n",
    "    else:\n",
    "        vlmcName=inputFile.stem\n",
    "    return vlmcName\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e3160a-2914-4299-a04f-270a5351132a",
   "metadata": {},
   "source": [
    "### Mine The VLMC From an Event Log ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c5bc5a-c669-42ba-9e36-e39a17805ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVLMC(inputFile):\n",
    "    readInputFile(inputFile)\n",
    "    vlmcName=getVLMCName(inputFile)\n",
    "    st=time.time()\n",
    "    mineProcess(ecfFile=f\"{os.getcwd()}/data/VLMC/{vlmcName}.ecf\",\n",
    "    infile=f\"{os.getcwd()}/data/converted/{vlmcName}.txt\",\n",
    "    vlmcfile=f\"{os.getcwd()}/data/VLMC/{vlmcName}.vlmc\", \n",
    "    nsim=\"1\", ntime=\"1\", alfa=\"1\")\n",
    "    vlmcTime=time.time()-st\n",
    "    print(f\"VLMC Mined In {vlmcTime}\")\n",
    "    return vlmcTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f062313f-da93-4b8e-be65-13ea20e2bbb2",
   "metadata": {},
   "source": [
    "### Compute Likelihood With VLMC ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06e5a97e-6747-485e-83f3-095e17793421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVLMCLikelyhood(vlmcName=None,traceFile=None):\n",
    "    st=time.time()\n",
    "    ecfFile=pathlib.Path(f\"{os.getcwd()}/data/VLMC/{vlmcName}.ecf\").absolute()\n",
    "    infile=pathlib.Path(f\"{os.getcwd()}/data/converted/{vlmcName}.txt\").absolute()\n",
    "    vlmcfile=pathlib.Path(f\"{os.getcwd()}/data/VLMC/{vlmcName}2.vlmc\").absolute()\n",
    "    vlmc=pathlib.Path(f\"{os.getcwd()}/data/VLMC/{vlmcName}.vlmc\").absolute()\n",
    "    \n",
    "    cwd=(ldir/pathlib.Path(traceFile.name.split(\".\")[0]))\n",
    "    cwd.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    getLikelyhood(\n",
    "        ecfFile=str(ecfFile),\n",
    "        infile=str(infile), #dataset used to learn the vlmc\n",
    "        vlmc=str(vlmc), #input VLMC to use\n",
    "        vlmcfile=str(vlmcfile),  #output VLMC\n",
    "        traces=str(traceFile), #traces to compute likelyhood\n",
    "        cwd=str(cwd),\n",
    "        outFile=\"out.mat\",nsim=\"1\", ntime=\"1\",alfa=\"1\")\n",
    "    liktime=time.time()-st\n",
    "    return liktime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c580bd-4fd7-45de-b619-a494ffe5dd92",
   "metadata": {},
   "source": [
    "### Compute uEMSC With VLMC Likelihood ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f63371-2fc7-437d-9f2a-100fe0d92027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uEMSCVLMC(inputLan=None,vlmcName=None):\n",
    "    st=time.time()\n",
    "    cwd=(ldir/pathlib.Path(inputLan.name.split(\".\")[0]))\n",
    "    cwd.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    traceLikName=\".\".join(inputLan.name.split(\".\")[0:-1])+\".lik\"\n",
    "    traceLikFile=cwd/pathlib.Path(traceLikName)\n",
    "    \n",
    "    modelLikName=vlmcName+\".vlmc.lik\"\n",
    "    modelLikFile=cwd/pathlib.Path(modelLikName)\n",
    "    \n",
    "    uEMSC=computeMuEMSC(traceLik=traceLikFile,modelLik=modelLikFile)\n",
    "    emsctime=time.time()-st\n",
    "    return uEMSC,emsctime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a0fdf9",
   "metadata": {},
   "source": [
    "### Collect VLMC Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a15b9cde-7896-4fcb-9187-4dff1e12505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectVLMCRes(resDir):\n",
    "    \"\"\"Collects VLMC results from .uemsc files.\n",
    "\n",
    "    This function searches for files with the '.uemsc' extension within the directory specified as input (and its subdirectories).\n",
    "    For each found file, it extracts:\n",
    "        - The log name (derived from the filename).\n",
    "        - The split index (extracted from the filename using a regular expression).\n",
    "        - The uEMSC value (read from the file content).\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the collected results with columns 'logname', 'split', and 'uemsc'.\n",
    "    \"\"\"\n",
    "    # Find all files with .uemsc extension in resDir and its subdirectories\n",
    "    matching_files = list(resDir.rglob(\"*.uemsc\"))\n",
    "    results=[]\n",
    "    # Iterate through each found file\n",
    "    for file in matching_files:\n",
    "        filePath=Path(file)\n",
    "        # Extract Logname from the filename (part before the first dot)\n",
    "        Logname=filePath.name.split(\".\")[0]\n",
    "        # Extract split index using regex (digits between 'gz' and '.uemsc')\n",
    "        splitIdx=int(re.findall(r'gz(\\d+)',filePath.name)[0])\n",
    "        # Load the uEMSC value from the file\n",
    "        uemsc=np.loadtxt(filePath)\n",
    "        # Add the extracted information as a new row in the results list\n",
    "        results+=[[Logname,splitIdx,uemsc]]\n",
    "    # Convert the results list to a Pandas DataFrame\n",
    "    return pd.DataFrame(results,columns=[\"logname\",\"split\",\"uemsc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7350a5-0ba0-442b-9c0e-1fee0e7fd5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectVLMCTime(resDir):\n",
    "    \"\"\"Collects VLMC timing results from .time files.\n",
    "\n",
    "    This function searches for files with the '.time' extension within the directory specified by 'resDir'\n",
    "    (and its subdirectories).\n",
    "    For each found file, it extracts:\n",
    "        - The log name (derived from the filename).\n",
    "        - The split index (extracted from the filename using a regular expression).\n",
    "        - Timing values (mctime, liktime, uemsctime) read from the file content.\n",
    "\n",
    "    Args:\n",
    "        resDir (pathlib.Path): The directory to search for .time files. This parameter is required.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the collected timing results with columns\n",
    "                          'logname', 'split', 'mctime', 'liktime', and 'uemsctime'.\n",
    "                          \n",
    "    Raises:\n",
    "        AttributeError: If resDir is None or not a valid Path object that supports rglob.\n",
    "    \"\"\"\n",
    "    # Find all files with .time extension in the specified directory and its subdirectories\n",
    "    # The resDir parameter is now directly used.\n",
    "    matching_files = list(resDir.rglob(\"*.time\"))\n",
    "    results=[]\n",
    "    # Iterate through each found file\n",
    "    for file in matching_files:\n",
    "        filePath=Path(file)\n",
    "        # Extract Logname from the filename (part before the first dot)\n",
    "        Logname=filePath.name.split(\".\")[0]\n",
    "        # Extract split index using regex (digits between 'gz' and '.time')\n",
    "        splitIdx=int(re.findall(r'gz(\\d+)',filePath.name)[0])\n",
    "        # Load the timing data from the file (expected to be an array-like structure)\n",
    "        time_data=np.loadtxt(filePath)\n",
    "        #print(Logname,splitIdx,time_data) # Original print statement, commented out\n",
    "        # Add the extracted information as a new row in the results list\n",
    "        # Assumes time_data contains at least three elements for mctime, liktime, and uemsctime\n",
    "        results+=[[Logname,splitIdx,time_data[0],time_data[1],time_data[2]]]\n",
    "    # Convert the results list to a Pandas DataFrame\n",
    "    return pd.DataFrame(results,columns=[\"logname\",\"split\",\"mctime\",\"liktime\",\"uemsctime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eacf83",
   "metadata": {},
   "source": [
    "### Road Traffic Fines Management Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5be5430-9d07-41f2-9a9d-d0b65c046ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeVLMCSCC():\n",
    "    print(\"########################################################\")\n",
    "    print(\"# This function orchestrates an end-to-end conformance checking pipeline using the Road Traffic Fine Management Process Dataset\")\n",
    "    print(\"# It involves mining a VLMC model from a training log, then evaluating test logs against this model\")\n",
    "    print(\"# by computing their likelihood and uEMSC scores.\") \n",
    "    print(\"# For the sake of the brevity, we will use only a single training log and two test log, however the code\")\n",
    "    print(\"# can be easily adapted to use different training log and is already designed to work with multiple test logs.\")\n",
    "    print(\"########################################################\")\n",
    "    \n",
    "\n",
    "    # Find all training log files matching the pattern in the trainLogDir\n",
    "    train_logs = list(trainLogDir.rglob(\"*.xes.gz[0].xes.gz\"))\n",
    "    # Find all test log files matching the pattern in the testLogDir\n",
    "    test_logs = list(testLogDir.rglob(\"*.xes.gz[0-1]_test.xes.gz\"))\n",
    "    # Mine VLMC Model from Event Log (using the first training log)\n",
    "    inputTrace = train_logs[0]\n",
    "    # Create the VLMC model and record the mining time\n",
    "    mctime = createVLMC(inputFile=inputTrace)\n",
    "    # Extract the base name for the VLMC from the input filename\n",
    "    vlmcName = \".\".join(inputTrace.name.split(\".\")[0:-2])\n",
    "    # Construct the expected path for the training trace language file\n",
    "    traceLan = ldir / Path(inputTrace.name.split(\".\")[0]) / Path(f\"{vlmcName}_trace.lan\")\n",
    "\n",
    "    # Loop over each test log file\n",
    "    for testTrace in test_logs:\n",
    "        testname=\".\".join(testTrace.stem.split(\".\")[0:-1])\n",
    "        # Process the test trace file (convert to suitable format)\n",
    "        # and compute the stochatic languange of the input test trace\n",
    "        readInputFile(inputFile=testTrace)\n",
    "\n",
    "        # Compute Test Language Likelihood (likelihood of the test trace given the VLMC)\n",
    "        # Construct the expected path for the test trace language file\n",
    "        testLan = ldir / Path(testTrace.name.split(\".\")[0]) / Path(f\"{testname}_trace.lan\")\n",
    "        # Calculate the likelihood and record the time\n",
    "        liktime = getVLMCLikelyhood(vlmcName=vlmcName, traceFile=testLan)\n",
    "\n",
    "        # Compute uEMSC (micro Event-based Sequence Conformance)\n",
    "        # Calculate the uEMSC and record the time\n",
    "        uEMSC, uemsctime = uEMSCVLMC(inputLan=testLan, vlmcName=vlmcName)\n",
    "\n",
    "        # Save the computed uEMSC and execution times to files\n",
    "        # Construct the path for the uEMSC result file\n",
    "        uEMSCFile = ldir / Path(testTrace.name.split(\".\")[0]) / Path(f\"{testTrace.name}.uemsc\")\n",
    "        # Construct the path for the time results file\n",
    "        uEMSCTimeFile = ldir / Path(testTrace.name.split(\".\")[0]) / Path(f\"{testTrace.name}.time\")\n",
    "        # Save the uEMSC value\n",
    "        np.savetxt(str(uEMSCFile), [uEMSC])\n",
    "        # Save the mining time, likelihood time, and uEMSC time\n",
    "        np.savetxt(str(uEMSCTimeFile), [mctime, liktime, uemsctime])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab12f1",
   "metadata": {},
   "source": [
    "### Compute Stochastic Conformance Checking via VLMC    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d178212",
   "metadata": {},
   "outputs": [],
   "source": [
    "computeVLMCSCC()\n",
    "vlmcRes=collectVLMCRes(resDir=ldir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de9b54-e6b3-45b1-8f53-bebdfbaebd85",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca35036-25ae-4706-b411-0073f42f94f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update global matplotlib parameters to set the default font size for plots to 18\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Define dictionary for custom styling of median properties in the box plot\n",
    "# 'linestyle=None' and 'linewidth=0' effectively make the median line invisible\n",
    "# 'color='firebrick'' sets the color, though it won't be visible with linewidth 0\n",
    "medianprops = dict(linestyle=None, linewidth=0, color='firebrick')\n",
    "\n",
    "# Define dictionary for custom styling of mean line properties in the box plot\n",
    "# 'linestyle=\"-\"' sets the mean line to be a solid line\n",
    "# 'linewidth=1.5' sets the thickness of the mean line\n",
    "# 'color='orange'' sets the color of the mean line to orange\n",
    "meanprops = dict(linestyle=\"-\", linewidth=1.5, color='orange')\n",
    "\n",
    "# Loop through each log name in the 'lognames' list (assuming 'lognames' is defined elsewhere)\n",
    "# 'enumerate' provides both the index (i) and the value (lname) for each item\n",
    "for i, lname in enumerate(lognames):\n",
    "    # Initialize an empty list 'x' to store the data arrays for the box plot for the current log name\n",
    "    x = []\n",
    "    # Initialize an empty list 'names' to store the labels for the box plot(s) for the current log name\n",
    "    names = []\n",
    "\n",
    "    # Assume 'vlmcRes' is a Pandas DataFrame containing the results.\n",
    "    # Filter 'vlmcRes' to get rows where 'logname' matches the current 'lname'.\n",
    "    # From these filtered rows, extract the 'uemsc' column values as a NumPy array.\n",
    "    # Append this array of uEMSC values to the list 'x'.\n",
    "    x += [vlmcRes[vlmcRes[\"logname\"] == lname][\"uemsc\"].values]\n",
    "    # Append the label \"VLMC\" to the 'names' list. This will be the label for the box plot.\n",
    "    names += [\"VLMC\"]\n",
    "            \n",
    "    # Create a new matplotlib Figure object for the plot.\n",
    "    # 'figsize=(10, 4)' sets the width to 10 inches and height to 4 inches.\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # Generate the box plot using the data and configurations:\n",
    "    #   x: The list of data arrays (in this case, a list containing one array of uEMSC values).\n",
    "    #   tick_labels: The labels for each box on the x-axis (in this case, [\"VLMC\"]).\n",
    "    #   showmeans=True: Instructs matplotlib to calculate and show the mean.\n",
    "    #   meanline=True: Instructs matplotlib to represent the mean as a line (using 'meanprops').\n",
    "    #   medianprops: Applies the custom styling defined earlier for the median.\n",
    "    #   meanprops: Applies the custom styling defined earlier for the mean line.\n",
    "    plt.boxplot(x, tick_labels=names, showmeans=True, meanline=True, medianprops=medianprops, meanprops=meanprops)\n",
    "    \n",
    "    # Set the label for the y-axis of the plot.\n",
    "    plt.ylabel(\"uEMSC\")\n",
    "    # Enable the grid on the plot for better readability of values.\n",
    "    plt.grid()\n",
    "    # Rotate the tick labels on the x-axis by 30 degrees.\n",
    "    # This is useful if the labels are long and might otherwise overlap.\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.title(\"uEMSC distrbutions on all the tested test logs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (Custom)",
   "language": "python",
   "name": "python3.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
